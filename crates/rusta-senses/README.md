# Sozna-sense
ğŸ› ï¸ Sozna-sense Build Sheet (v0)

Goal: Implement the perception core (ByteFrame â†’ Detect â†’ Adapter â†’ (emb, trace)) with all practical upgrades, test harness, and error handling.
Scope: Text, Audio, vision, Binary adapters. Deterministic enough to be stable; no salience/fusion yet.

1. Core Modules

ByteFrame struct

Fields: data, ts, source_id.

Optional: hint (ext/mime), policy.

Source = ingest (file, mic, cam, stdin, http).

Detector

Magic byte headers: PNG, JPEG, WAV, MP3, WebP, GIF, PDF, ZIP.

UTF-8/UTF-16 BOM check.

Fallback: Binary.

Trace tag: det:<modality>(params).

Adapters

TextAdapter: Conv1D stem (k=5, stride=1, h=256), GELU, projâ†’512.

AudioAdapter: Decodeâ†’PCMâ†’monoâ†’resample16k, STFT (1024/256), mel=80, patch=8, projâ†’512.

visionAdapter: Decodeâ†’RGB(sRGB), EXIF orient, normalize [0,1], patchify 16Ã—16, projâ†’768.

RawByteAdapter: norm bytes/255, truncate/stride, projâ†’512.

Trace

Append tags at each step: detector, adapter, transform, projection, error/fallback.

Example: det:audio(fmt=mp3â†’pcm,sr=16k) â†’ downmix:mono â†’ resample:polyphase16k â†’ stft 1024/256 â†’ mel=80 â†’ patch_t=8 â†’ proj d=512.

2. Config Defaults
Modality	Front-end	Defaults	Output
Text/Code	Conv1D stem â†’ proj	k=5, h=256, d_model=512	(T, 512)
Audio	STFTâ†’mel80â†’patch8â†’proj	sr=16k, win=1024, hop=256	(N, 512)
vision	patchify 16Ã—16â†’proj	normalize=[0,1], d_model=768	(N, 768)
Binary	byte norm/strideâ†’proj	d_model=512	(T, 512)
3. Tests (Golden Kit)

Text: "fn main(){}", multilingual, JSON.

Audio: sine1kHz, short speech, silence.

vision: checkerboard, colorbars, EXIF-rotated JPEG.

Binary: random bytes, corrupted JPEG, zip stub.

Checks:

Routing correctness (headers + UTF-8).

Golden embeddings equality.

Determinism across runs (same inputs, same config).

Error/fallback traces visible.

Size/time guard works (e.g., >16 MB â†’ truncated).

4. Error & Safety Gates

Max frame size: 16 MB (truncate/stride if bigger).

Session cap: 256 MB.

Decode timeout: 5s local / 15s net.

ZIP bomb guard: no deep introspection.

Sandboxed decoders optional flag.

Status tags: ok | warn | degraded | fail.

5. Deliverables

Crate: sozna-sense

Public API: process(ByteFrame) -> SenseOut.

SenseOut: (emb, trace, sidecar?).

Unit tests: golden fixtures.

Benchmarks: tokens/sec, patches/sec.

Minimal CLI harness: sense file.png â†’ prints trace + shape.

6. Milestones

M1 Core: Detector + Adapters + Trace.

M2 QA: Golden tests + determinism checks + error taxonomy.

M3 Ergonomics: Config via TOML/JSON, CLI harness, bench numbers.
Perception core: **ByteFrame â†’ Detect â†’ Adapter â†’ (emb, trace)**

Crates:
- sense-core
- sense-detector
- sense-adapter-{text,audio,vision,binary}
- sense-cli

Build:
```
cargo build --workspace
```

CLI:
```
cargo run -p sense-cli -- <path-to-file>
```
# Soznaâ€‘sense â€” vision & Architecture (v0)

**Owner:** Huy
**Date:** 2025â€‘08â€‘27
**Scope:** Perception layer for Sozna â€” ingestionâ†’detectionâ†’adapterâ†’embeddings + trace. No training, salience, or fusion in v0.

---

## 1) Purpose & Positioning

Soznaâ€‘sense turns arbitrary digital inputs into **modelâ€‘ready embeddings** plus a **transparent trace** of how they were formed. It is modalityâ€‘aware yet philosophyâ€‘neutral. It does *perception only* and exposes a single clean contract upward to any downstream model (e.g., Byte LM / Transformer) and sideways to memory/agent layers.

**Why:**

* Keep sensing simple, fast, and explainable.
* Unify disparate sources (files, mic, camera, HTTP) under one interface.
* Decouple OS/devices from modeling; preserve determinism and reproducibility.

**Nonâ€‘goals (v0):** temporal streaming, salience, fusion, AST parsing, PDF/ZIP extraction internals, longâ€‘running device loops.

---

## 2) Design Principles

* **Universal intake:** everything starts as bytes.
* **One clean contract:** embeddings `(tokens/patches Ã— d_model)` + `trace[]`.
* **Modular & pluggable:** detector, adapters, and transforms are replaceable.
* **Deterministic:** same bytes + config â‡’ same embeddings (eval mode).
* **Efficient first:** singleâ€‘pass detection; sampleâ€‘efficient frontâ€‘ends.
* **Explainable:** every step appends a compact, stable trace tag.
* **No lockâ€‘in:** independent of any specific downstream model architecture.

---

## 3) External Contracts (Stable)

**Input:** `ByteFrame` (opaque bytes + optional hints).
**Output:** `SenseOut` (embeddings, trace).

**ByteFrame (conceptual):**

* `data`: raw bytes
* `ts`: timestamp (monotonic + wall)
* `source_id`: path/URL/device tag

**SenseOut:**

* `emb`: 2â€‘D matrix `(seq_len_or_patches, d_model)`
* `trace`: ordered, humanâ€‘readable tags (e.g., `"utf8:ok"`, `"stft win=1024 hop=256"`, `"patch=16"`, `"proj d=512"`).

Contract invariants:

* Never blocks on devices/network (thatâ€™s ingest).
* Never writes to disk or phones home.
* Errorâ€‘tolerant: unknown or malformed blobs route to Binary/Unknown with trace.

---

## 4) System Overview

**Pipeline:** *raw bytes* â†’ **modality detection** â†’ **adapter** â†’ **frontâ€‘end transforms** â†’ **embeddings** + **trace**.

**Components:**

1. **Ingest (adjacent module, not inside sense):** files/repos, HTTP, mic/cam, stdin; bounds, chunking, normalization; emits `ByteFrame`s.
2. **Detector (inside sense):** magicâ€‘byte checks for PNG/JPEG/WAV/MP3 (+ optional PDF/ZIP for routing), UTFâ€‘8 vs binary heuristic; outputs a label + hints + confidence (trace only).
3. **Adapters:** one per modality. v0: Text, Audio, vision, Binary/Unknown.
4. **Transforms library:** patchify, STFT, mel, logâ€‘mel, normalization; reusable across adapters.

---

## 5) Adapters (v0 Defaults)

**Text (includes code):** learned Conv1D stem over normalized bytes/chars; project to `d_model=512`.
*Rationale:* vocabâ€‘free; learns braces/subwords; fast.

**Audio (WAV/MP3â†’PCM):** STFT â†’ mel(80) â†’ log â†’ temporal patchify (t=8) â†’ project to `d_model=512`.
*Rationale:* SOTAâ€‘standard, sampleâ€‘efficient, stable.

**vision (PNG/JPEGâ†’RGB):** ViTâ€‘style nonâ€‘overlapping patchify (16Ã—16), flatten, project to `d_model=768`.
*Rationale:* strong baseline; easy, fast.

**Binary/Unknown:** byte normalization â†’ small projection to `d_model` (configurable).
*Rationale:* failâ€‘safe; perception never hardâ€‘fails.

**Config (v0 defaults):**

* Text: `d_hidden=256, k=5, stride=1, norm=on, GELUâ€‘like`
* Audio: `sr=16k, win=1024, hop=256, mel=80, patch_t=8`
* vision: `patch=16, normalize=[0,1]`
* `d_model`: `512 (text/audio)`, `768 (vision)`

All parameters are runtimeâ€‘configurable (e.g., TOML/JSON). Trace records actual values used.

---

## 6) Tracing & Observability

* Every detection/transform appends a tag.
* Trace returned with embeddings and emitted at debug log level.
* Examples:

  * Text: `utf8:ok â†’ conv1d k=5 h=256 â†’ gelu â†’ proj d=512`
  * Audio: `wav 16k â†’ stft 1024/256 â†’ mel=80 â†’ patch_t=8 â†’ proj d=512`
  * vision: `jpeg â†’ rgb norm â†’ patch=16 â†’ proj d=768`
* Purpose: reproducibility, fast diffing between runs, issue triage.

---

## 7) Performance, Reliability

* **Throughput:** singleâ€‘threaded baseline should be memoryâ€‘bandwidthâ€‘bound; enable parallel decode where safe later.
* **Memory bounds:** streaming/patch buffers; avoid full copies.
* **Errors:** propagate as recoverable results; note failure points in trace; route to Binary/Unknown when possible.

---

## 8) Testing & QA (Golden Kit)

**Fixtures:**

* Text: `"fn main(){}"`, multilingual UTFâ€‘8, long JSON, markdown.
* Audio: 1 kHz sine @16k WAV; short speech clip; silence.
* vision: checkerboard, color bars, small JPEG/PNG.
* Routing: PNG header, UTFâ€‘8 text, random bytes.

**Tests:**

* Golden embeddings equality (bitâ€‘exact within tolerance) + exact trace strings.
* Routing correctness for headers and UTFâ€‘8 heuristic.
* Determinism over repeated runs.
* Performance smoke tests under size caps.
* Security: reject absurd sizes; bounded decode time.

**Definition of Done (v0):**

* All four adapters pass golden tests.
* Detector routes all fixtures correctly.
* Configurable params are recorded in trace.
* No network/file I/O inside sense; no panics on malformed inputs.
* Bench doc: tokens/sec (text), patches/sec (audio/vision) on a reference machine.

---

## 9) Security & Privacy

* No persistence in sense; stateless between calls.
* No hidden network; pure local compute.
* Size/time limits at ingest; clear error paths.

---

## 10) Extensibility (Postâ€‘v0 Growth)

* **Salience preâ€‘filters:** drop blank patches/frames/filler spans; compute savings.
* **Temporal continuity:** sliding windows, overlapâ€‘add stats, temporal pooling.
* **Fusion hooks:** timestamps & spatial anchors for crossâ€‘modal attention; alignment metadata.
* **Preâ€‘attention focus:** region proposals / energyâ€‘based gating before heavy modeling.
* **Learning feedback:** adapter fineâ€‘tuning during endâ€‘toâ€‘end training (optâ€‘in).
* **More modalities:** PDF/ZIP routing to external extractors; vector graphics; sensor logs.

---

## 11) Integration Points (Sozna stack)

* **Upstream model:** consumes embeddings; adds positional encodings.
* **Memory (Sigars):** store trace + checksums as evidence; enable audit trails.
* **Agent/Tools:** traces inform diagnostics (â€œspeechâ€‘likeâ€, â€œlowâ€‘energy framesâ€ flags).
* **UI:** display perâ€‘sample trace; let users diff traces across runs.

---

## 12) Roadmap & Milestones

**M0 â€” Spec lock (today)**

* This document approved; invariants frozen for v0; open questions listed.

**M1 â€” Core pipeline**

* Detector (magic bytes + UTFâ€‘8 heuristic).
* Adapters: Text, Audio, vision, Binary with defaults.
* Trace plumbed endâ€‘toâ€‘end.
* Golden fixtures minted.

**M2 â€” QA & Bench**

* Golden equality + routing tests stable.
* Determinism proven.
* Throughput numbers recorded on reference box.

**M3 â€” Developer ergonomics**

* Config via TOML/JSON.
* Clear errors & trace docs.
* Minimal examples (CLI/UI is *out of scope* but a tiny harness can live beside the crate).

**Exit criteria for v0:** ship a crate that converts ByteFrames â†’ (emb, trace) for Text/Audio/vision/Binary reliably.

---

## 13) Open Questions (to answer later)

1. **Text frontâ€‘end scale:** do we want dynamic byte/char mixed inputs or stick to one path v0?
2. **Audio resampling:** fix to 16 kHz at ingest or allow 8/22.05/48 kHz with a clear trace tag?
3. **vision normalization:** stick to `[0,1]` or offer visionNet stats as a toggle in v0.1?
4. **Binary adapter dimension:** tie to `d_model_text` or be independently configurable?
5. **Trace format:** plain strings (humanâ€‘first) vs compact enum codes (machineâ€‘first) + a pretty printer.
6. **Checksum choice:** blake3 vs xxhash; how strict do we want reproducibility gates.
7. **Failure policy:** when decode fails (e.g., corrupted JPEG), do we always fallback to Binary or expose error state to caller to decide?

---

## 14) Session Plan (to reduce overwhelm)

**Session A (â‰¤90 min):**

* Freeze config defaults table (this doc).
* Finalize detector label list + routing matrix.
* Write the golden fixtures list & acceptance checks (bulleted, no code).

**Session B (â‰¤90 min):**

* Draft trace taxonomy (exact tag strings).
* Define error taxonomy & recovery paths (fallbacks vs hard errors).
* Walk through 5 endâ€‘toâ€‘end examples on paper (what the trace should look like).

**Session C (â‰¤90 min):**

* Lock v0 DoD; create the benchmark plan (which inputs, what metrics).
* Review open questions; pick defaults for v0; defer rest to v0.1.

---

## 15) Oneâ€‘Page Defaults Table (for quick reference)

| Modality      | Frontâ€‘end                                | Defaults                                                                 | Output             |
| ------------- | ---------------------------------------- | ------------------------------------------------------------------------ | ------------------ |
| **Text/Code** | learned Conv1D stem â†’ proj               | `k=5`, `stride=1`, `d_hidden=256`, `d_model=512`, `norm=on`, `GELUâ€‘like` | `(T, 512)`         |
| **Audio**     | STFT â†’ mel(80) â†’ log â†’ patch\_t=8 â†’ proj | `sr=16k`, `win=1024`, `hop=256`, `mel=80`, `patch_t=8`, `d_model=512`    | `(N_patches, 512)` |
| **vision**     | patchify 16Ã—16 â†’ proj                    | `normalize=[0,1]`, `patch=16`, `d_model=768`                             | `(N_patches, 768)` |
| **Binary**    | byte norm â†’ proj                         | `d_model=512 (configurable)`                                             | `(T, d_model)`     |

**Detector order:** headers â†’ UTFâ€‘8 vs binary â†’ fallback.
**Error policy:** prefer recoverable fallback with explicit trace; never panic.

---

## 16) Glossary

* **Adapter:** modalityâ€‘specific pipeline that turns bytes into embeddings.
* **Frontâ€‘end:** transforms inside an adapter (STFT, patchify).
* **Trace:** ordered tags describing sensing steps/params.
* **Patch (temporal):** grouped frames treated as one token.
* **ByteFrame:** uniform envelope for bytes from any source.

---

## 17) Summary

Soznaâ€‘sense v0 is deliberately narrow and stable: **ByteFrame â†’ Detect â†’ Adapter â†’ (emb, trace)**. It favors speed, determinism, and clarity, leaving salience/streaming/fusion for postâ€‘v0. With the contracts and defaults here, you can implement confidently without touching philosophy every day â€” build the small, sharp knife first.

---

## 18) Extensions & Future Directions (Comprehensive)

**Goal:** Make all plausible growth paths explicit so v0 stays minimal while the northâ€‘star is visible.

### 18.1 Modalities to Add

* **Video:** RGB frames â†’ patchify per frame + temporal stride/patching; opticalâ€‘flow or frameâ€‘diff tokens; audioâ€‘video sync by timestamps.
* **Codeâ€‘aware Text:** optional AST/CFG sideâ€‘channel; symbol tables; doc anchors; compiler log adapters (e.g., `rustc`, `clippy`).
* **Documents:** PDF â†’ external extractor (text/spans/visions/tables) â†’ route to Text/vision; **OCR** for scanned PDFs.
* **Tabular / Logs / Timeâ€‘series:** schemaâ€‘aware encoders; delta/derivative channels; calendar/seasonality marks.
* **Sensors:** IMU, GPS, LiDAR/Depth, 3D point clouds (voxel/BEV tokens), biosignals (ECG/EEG) with bandâ€‘power features.
* **UI/Screen:** screen capture frames + DOM/accessibility tree hooks when available.

### 18.2 Temporal & Streaming

* Sliding windows with overlap; online normalization (running mean/var); EMA statistics.
* Changeâ€‘point detection; eventized encodings (spikeâ€‘like) for sparse updates.
* Stream contracts: backpressure, bounded queues, watermarks, late frames policy.
* Latency budgets per modality (target p50/p95/p99) + jitter caps.

### 18.3 Salience & Preâ€‘Attention

* Energy/entropy gates (audio lowâ€‘energy frames, blank vision patches, filler text regions).
* ROI discovery: simple heuristics â†’ learned region proposals.
* Multiâ€‘scale pyramids: coarse tokens first; refine ROIs with smaller patches.
* Adaptive patching: patch size chosen by content (e.g., 16â†’8 on highâ€‘detail zones).

### 18.4 Fusion & Alignment

* Alignment metadata: timestamps, spatial coords, object IDs, source lineage.
* Crossâ€‘attention fusion blocks; late vs early fusion toggles.
* Token binding graph: edges across modalities (e.g., `(caption token) â†” (vision patch)`), exportable to memory (Sigars) as evidence links.

### 18.5 Learning in the Frontâ€‘Ends

* **Phase 1:** classical fixed DSP (STFT/patchify) for stability.
* **Phase 2:** endâ€‘toâ€‘end fineâ€‘tuning heads (conv stems, mel projection).
* **Selfâ€‘supervision:** masked modeling (span masking for text/audio/video), contrastive alignment (CLIPâ€‘style), BYOLâ€‘A/SimCLR variants; augmentation policies per modality.
* **Curriculum:** start small (clean speech, simple visions, short code) â†’ scale diversity.

### 18.6 Quality, Uncertainty, & Diagnostics

* Perâ€‘token quality scores (SNR, blur, clipping, OCR confidence) propagated with embeddings.
* Uncertainty estimates (aleatoric proxies) as an auxiliary vector alongside `emb`.
* Selfâ€‘diagnostics: â€œdecodeâ€‘suspectâ€, â€œlowâ€‘energyâ€, â€œnonâ€‘utf8â€, â€œheaderâ€‘mismatchâ€.

### 18.7 Robustness, Safety & Privacy

* Adversarial defenses: input sanitization, checksum/length sanity, JPEG bomb detection.
* Privacy filters: PII redaction hooks for text/visions; mic/cam hard mutes; onâ€‘device only mode.
* Sandboxing: decode in a constrained process; time/CPU/memory guards.

### 18.8 Performance Engineering

* Vectorized kernels; mixed precision where safe; memory pooling.
* Batching across samples (microâ€‘batch) and within sample (patch batches).
* CPU/GPU backâ€‘ends; fallback to pureâ€‘CPU; SIMD feature detection.
* Caching: decoded RGB/PCM caches keyed by checksum; traceâ€‘stamped.

### 18.9 Packaging & Deploy Targets

* **Edge:** WebAssembly/WASI for browser/desktop; mobile (Android/iOS) with NEON.
* **Server:** gRPC/QUIC stream APIs; zeroâ€‘copy buffers.
* **Rust crate stability:** semver guarantees for contracts; feature flags per modality.

### 18.10 Provenance & Auditability

* Content hashes (blake3) everywhere; chain of custody from `ByteFrame` â†’ trace â†’ memory.
* Replay files: minimal sidecar format to reproduce sensing (config + checksums + offsets).

### 18.11 Plugin API (v1.0+)

* Adapter registry: dynamic discovery & capability descriptors (modalities, params, throughput).
* ABI stability plan; reference adapter templates; conformance tests.

---

## 23) What Stays Nonâ€‘Negotiable

* ByteFrame in; (emb, trace) out.
* No device I/O or network inside sense.
* Determinism preference; explicit trace for everything.
* Recoverable failure paths; safe fallbacks; no silent drops.

---

## 24) Learning Feedback Mechanisms

**Definition:** The ability of adapters/frontâ€‘ends to adjust their parameters in response to downstream training signals or explicit agent feedback.

### Modes of Feedback

* **Gradientâ€‘based (endâ€‘toâ€‘end):** downstream loss gradients propagate back into the frontâ€‘end (e.g., Conv1D, STFT projection, patch projections) so that sensing features coâ€‘evolve with the model.
* **Reinforcement / Rewardâ€‘based:** higherâ€‘level agent rewards (e.g., task success, code compiles, ASR accuracy) influence adapter hyperâ€‘parameters or gating choices.
* **Metaâ€‘learning / Curriculum:** frontâ€‘ends schedule their complexity (start fixed; allow fineâ€‘tuning once core model stabilizes).

### Examples

* **Text:** Conv1D filters sharpen to capture common subword boundaries or brace patterns because downstream language modeling loss rewards it.
* **Audio:** mel filter emphasis shifts slightly to better capture speech formants or suppress noise, guided by ASR error reduction.
* **vision:** adaptive patch resolution or normalization improves accuracy on detection tasks when allowed to update.

### Control & Safety

* Feedback is **optâ€‘in and gated by config**: by default, v0 runs fixed transforms for determinism.
* Enablement only in training mode; evaluation/inference keeps adapters frozen.
* Gradients are clipped/regularized to prevent catastrophic drift in lowâ€‘level sensing.

### Trace Extensions

* Trace should log whether an adapter was frozen or learnable.
* If learnable, include stepâ€‘size or epoch markers (e.g., `"text: conv1d learnable, lr=1eâ€‘4"`).

### Roadmap Placement

* **v0:** frozen transforms, no feedback.
* **v1.1+:** allow fineâ€‘tuning of projection layers and filterbanks.
* **v1.2+:** adaptive patching/learned salience gates.
* **v2.0:** reinforcement/agentâ€‘driven feedback where AIâ€™s own success/failure alters sensing policies.

### Rationale

## Learning feedback makes Soznaâ€‘sense more than static preprocessing â€” it becomes part of the living loop, where perception adjusts because the AI itself *needs* it to solve tasks better.

## 25) RawByteAdapter (Binary/Unknown) â€” Full Spec

**Purpose:** Guarantee perception never hardâ€‘fails when detection canâ€™t confidently classify an input or decoding fails. Provides a safe, deterministic embedding for arbitrary bytes.

**Detection triggers:**

* No known magic bytes matched OR header matched but decode failed.
* UTFâ€‘8 heuristic negative (low printable ratio / invalid sequences).
* Caller explicitly routes to Binary.

**Preprocessing / Normalization:**

* **Byte scale:** map `u8 â†’ f32` by `x / 255.0` (configurable to zâ€‘score if caller provides mean/std).
* **Stride/truncation:** enforce `max_len_bytes` (config). If `len > max`, either *truncate tail* or *fixedâ€‘stride subsample*; record policy + offsets in trace.
* **Chunking (optional):** for very large blobs, process in fixed windows and concatenate embeddings; include `(start..end)` byte ranges in trace.

**Projection:**

* **Linear projection** from `R^{TÃ—1}` to `R^{TÃ—d_model_bin}` (`d_model_bin` default = 512, independent toggle to tie with text).
* Optional **LayerNorm** to stabilize scale across wildly different inputs.

**Trace (examples):**

* `binary â†’ norm bytes/255 â†’ stride=4 start=0 len=8MB â†’ proj d=512`
* `binary â†’ chunk[0..1MB],[1..2MB] â†’ proj d=768`

**Guarantees:**

* Deterministic outputs given same bytes + config.
* Never attempts deep decode (no ZIP/PDF introspection).
* Bounded memory/latency via `max_len_bytes`, `stride`, and chunking.

**Failure policy:**

* If the *router* sent an input here due to a failed decode (e.g., corrupted JPEG), the trace must include `reason=decode-failed:<codec>`.

---

## 26) Concrete Upgrades to Lock In Now (not fluff)

These tighten the core without expanding scope.

### 26.1 Detector & Routing Accuracy

* Add **WebP, GIF, MP4/MOV/AVI** header checks (route MP4 to *Binary* for now).
* **PDF/ZIP**: detect reliably but keep *containerâ€‘only* routing (no introspection yet).
* **UTFâ€‘16/UTFâ€‘32 & BOM** handling: if BOM present, treat as Text path with correct decoding; else fall back to Binary on ambiguous mixed encodings.
* Record **`detector:label(conf=â€¦)`** in trace.

### 26.2 vision Correctness

* Fix **color space** assumptions: treat inputs as **sRGB**, convert to linearâ€‘light *or* stay in sRGB but record `colorspace` in trace (choose one policy).
* Respect **EXIF orientation**; record applied rotation/flip in trace.
* Define channel order **HÃ—WÃ—C, C=RGB** (no BGR); dtype f32 in `[0,1]` before patchify.

### 26.3 Audio Correctness

* **Channel policy:** downmix to mono with documented weights; record original channels.
* **Resampling:** lock to **16 kHz** with a deterministic resampler; record method (e.g., polyphase).
* DCâ€‘offset removal + optional **loudness normalization** (EBU R128â€‘lite) *off by default*; if used, trace it.

### 26.4 Text Correctness

* **Unicode normalization** policy (NFC vs NFKC); newline normalization (`  â†’  `).
* Optional **whitespace collapse** flag (off by default) â€” only for pathological inputs; trace it.

### 26.5 Positioning & Tokens

* Define downstream expectation for **positional encodings**: senses do **not** add them. Provide optional **perâ€‘sample CLS token** recommendation (added by downstream model) and a **metadata sidecar** (lengths, patch grid, sample rate) to help positioners.

### 26.6 Trace Schema v0.1 (still humanâ€‘readable)

* `phase: detector|adapter|transform`, `name`, `params(key=value,â€¦)`, `reason?`, `ranges?`.
* Stable ordering; machineâ€‘parseable without losing readability.

### 26.7 Reproducibility & Safety

* Standardize on **blake3** for content hashes; include first 8 bytes as short id in trace.
* **ZIP bomb guard:** cap total uncompressed ratio; refuse deep inspection (postâ€‘v0).
* JPEG/PNG decode done in **sandboxed** helper (optional flag) with time/memory guards.

### 26.8 Config Hygiene (principle only)

* Keep userâ€‘facing config small; record effective runtime values in trace if they differ due to enforced caps.

### 26.9 Tiny Quality Sideâ€‘Vector (toggle only)

* Allow adapters to emit an optional `qvec` alongside `emb` (e.g., perâ€‘token energy/blank flag). Toggle off by default; no rationale text in spec.

---

## 27) Determinism Matrix (What can change outputs & how to lock it)

| Factor                       | Risk                     | Lockâ€‘In Policy                                                                         |
| ---------------------------- | ------------------------ | -------------------------------------------------------------------------------------- |
| Random init (learned layers) | Nonâ€‘repro emb            | Fix seed; eval mode; persist weights hash in trace                                     |
| Decode libs/versions         | JPEG/PNG/STFT impl drift | Record decoder + version in trace; optional sandboxed decoder feature flag             |
| Floatingâ€‘point math          | Minor nondet across HW   | Use deterministic kernels when available; disable TF32; record backend/device in trace |
| Multithreading               | Reordering/precision     | Singleâ€‘thread eval by default; record thread count when >1                             |
| Resampling/filter params     | Spectral differences     | Pin resampler method + taps; record in trace                                           |
| Unicode normalization        | Token boundary drift     | Fix to NFC (or chosen policy) and trace it                                             |
| Color space/EXIF             | Visual mismatch          | Fix sRGB policy + EXIF orientation handling; trace both                                |
| Caps/stride                  | Length/coverage changes  | Record enforced caps + stride policy with byte ranges                                  |

---

## 28) Routing Matrix (Detection â†’ Adapter â†’ Required Hints â†’ Trace Tags)

| Detected Type         | Primary Adapter                | Required Decode/Hints   | Canonical Trace Start                      |                                 |
| --------------------- | ------------------------------ | ----------------------- | ------------------------------------------ | ------------------------------- |
| PNG/JPEG (sRGB)       | vision                          | decodeâ†’RGB, EXIF orient | `det:vision(fmt=jpeg,orient=...)`           |                                 |
| WAV/PCM               | Audio                          | sr, channels            | `det:audio(fmt=wav,sr=16k,mono)`           |                                 |
| MP3                   | Audio                          | decodeâ†’PCMâ†’sr16k mono   | `det:audio(fmt=mp3â†’pcm,sr=16k,mono)`       |                                 |
| UTFâ€‘8 / UTFâ€‘16(BOM)   | Text                           | norm policy             | \`det\:text(utf8                           | utf16,bom=...)\`                |
| PDF/ZIP               | Binary (container)             | none (no introspection) | \`det\:container(fmt=pdf                   | zip)\`                          |
| WebP/GIF              | vision (if decode on) or Binary | decode toggle           | \`det\:vision(fmt=webp                      | gif)`or`det\:binary(fmt=webp)\` |
| Unknown/Failed decode | Binary                         | â€”                       | `det:binary(reason=decode-failed:<codec>)` |                                 |

---

## 29) Sidecar Metadata Spec (for downstream PE/CLS)

Per sample, return a lightweight sidecar alongside `emb` & `trace`:

* `lengths`: token/patch counts per stream
* `grid`: vision patch grid `(H_patches, W_patches)`
* `audio`: `{sr: 16000, hop: 256, win: 1024, patch_t: 8}`
* `text`: `{norm: NFC, newline: "
  "}`
* `binary`: `{stride: 4, chunks: [[0,1048576], ...]}`
* `quality?`: optional `qvec` shape descriptor
* `hash`: blake3 short id
  This sidecar enables positioners and downstream fusers without touching the core contract.

---

## 30) Error / Status Taxonomy

**Levels:** `ok`, `warn`, `degraded`, `fail` (with fallback).
**Classes:** `decode`, `bounds`, `config`, `device`, `format`, `container`.
**Examples:**

* `warn:audio.bounds: resample to 16k applied`
* `degraded:vision.decode: webp decoder unavailable â†’ binary`
* `fail:text.format: invalid UTFâ€‘16 w/out BOM â†’ binary`
  All statuses append to trace and are emitted via diagnostics.

---

## 36) Ingest Checklist (so we can build immediately)

* Sources enabled: File, HTTP, Mic (16k), Cam (RGB), STDIN.
* Caps: max frame 16 MB; session cap 256 MB; timeouts 5s local/15s network.
* Hints populated: filename/ext, sr/channels, WxH when known.
* ByteFrame fields: `data`, `ts`, `source_id` (others optional).
* Backpressure: bounded queue size N; drop policy = coalesce for streams.
* Logging: perâ€‘frame short id optional; errors surfaced without panics.

---

**Result:** With these sections, weâ€™re not just â€œclearâ€â€”weâ€™re **buildâ€‘ready**. No ambiguity on determinism, routing, metadata, errors, benches, safety, repo layout, canonical traces, or ingest. This is the full spec we can execute against.
sozna-sense/
â”œâ”€ Cargo.toml # workspace
â”œâ”€ rust-toolchain.toml # (optional) pin toolchain
â”œâ”€ README.md # project overview
â”œâ”€ LICENSE # choose MIT/Apache-2.0
â”œâ”€ .gitignore
â”œâ”€ .editorconfig
â”œâ”€ .github/
â”‚ â””â”€ workflows/
â”‚ â”œâ”€ ci.yml # build + test
â”‚ â””â”€ lint.yml # fmt + clippy
â”œâ”€ crates/
     rusta-sense #public API
â”‚ â”œâ”€ sense-core/ #  ByteFrame, SenseOut, Adapter trait
â”‚ â”œâ”€ sense-detector/ # modality detection
â”‚ â”œâ”€ sense-adapters/
â”‚ â”‚ â”œâ”€ text/ # TextAdapter (Conv1D stem â†’ proj)
â”‚ â”‚ â”œâ”€ audio/ # AudioAdapter (STFTâ†’melâ†’patch)
â”‚ â”‚ â”œâ”€ vision/ # visionAdapter (patchify 16Ã—16)
â”‚ â”‚ â””â”€ binary/ # RawByteAdapter
â”‚ â””â”€ sense-cli/ # tiny CLI: `sense <path>`
â”œâ”€ configs/
â”‚ â”œâ”€ default.toml # defaults for all adapters
â”‚ â””â”€ examples/ # per-modality variants
â”œâ”€ tests/
â”‚ â”œâ”€ fixtures/
â”‚ â”‚ â”œâ”€ text/
â”‚ â”‚ â”‚ â”œâ”€ utf8_hello.txt
â”‚ â”‚ â”‚ â”œâ”€ utf16_bom.txt
â”‚ â”‚ â”‚ â””â”€ long.json
â”‚ â”‚ â”œâ”€ audio/
â”‚ â”‚ â”‚ â”œâ”€ sine1k_16k.wav
â”‚ â”‚ â”‚ â”œâ”€ speech_short.wav
â”‚ â”‚ â”‚ â””â”€ silence.wav
â”‚ â”‚ â”œâ”€ vision/
â”‚ â”‚ â”‚ â”œâ”€ checker_128.png
â”‚ â”‚ â”‚ â”œâ”€ colorbars.jpg
â”‚ â”‚ â”‚ â””â”€ exif_rot90.jpg
â”‚ â”‚ â””â”€ binary/
â”‚ â”‚ â”œâ”€ random.bin
â”‚ â”‚ â”œâ”€ zip_stub.zip
â”‚ â”‚ â””â”€ pdf_stub.pdf